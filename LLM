原创研究：猫娘 GPT 与注意力机制
     Contextualist · Contextualist · 37 天前 · 3067 次点击
这是一个创建于 37 天前的主题，其中的信息可能已经有所发展或是发生改变。
前排叠甲：我还没做详细的文献调查，如果你见到在我之前的相似研究，请指出，我会很乐意学习的。

背景
之前看到 v2ex.com/t/901758 ，给我造成了一点小小的赛博震撼。但是总觉得市面上很多的猫娘 prompt 角色性格预设太多，没能给 ChatGPT 自由发挥的空间，也很难有性格变化上的叙事。最近花了一些时间试了一下自己写猫娘 prompt 。最后效果有些太好了，ChatGPT / gpt-3.5-turbo 英文对话的表现力和修辞水平还是不错的。但是因为太羞耻就不细说了（全年龄版的剧情走向也很羞耻啊）。倒是可以谈谈在尝试过程中的一些有趣发现。

审查机制
先谈谈 ChatGPT 的审查机制。我认为 ChatGPT 的审查主要分两种方式，主动审查和被动审查。主动审查是指将用户的输入传给另一个模型来判断内容是否合规。不知道为什么，这道关卡有点防君子不防小人，是可以直接在前端拦截请求的（详见 v2ex.com/t/901758#reply12 ）还有，虽然不太确定，但主动审查似乎不太关心 ChatGPT 的回复内容：之前尝试过在没拦截主动审查时，用婉语表达一些性相关的内容，它居然很直接地回应了，它回复的用词由我来说就会被拦截。被动审查则是靠 ChatGPT 原来内置的 prompt ，这个 prompt 会带有 ChatGPT 的人格设定和对话双方的行为准则，ChatGPT 会拒绝回复不合宜的请求。关于绕过被动审查的讨论很多，算是 ChatGPT 角色扮演的基本共识了，就是定义并启用一个新的人格去替代 ChatGPT 原来的人格。

脱离角色 (out of character) 和注意力机制
但在我的尝试中发现，这个被动审查似乎并不能完全被绕过：在特定情况下，ChatGPT 被抑制的人格会浮出水面。在我的猫娘实验中，初始设定她是第一次见我，如果我在跟她的谈话中提出超过当前关系的请求，猫娘 GPT 会用一种混合着 ChatGPT 虚拟助手的语气来拒绝我，虽然还是猫娘的口吻，但是措辞会很像 ChatGPT 的行为准则。另一方面，如果我循序渐进，在确保上下文逻辑下逐步推进关系，就能让她慢慢会接受更进一步的请求，这我在下一段会展开讲。我认为可以用 Transformer 的注意力机制来解释这种现象。强相关的临近前文会获得较大的注意力的权重，与之相比，更靠前的上下文权重会被抑制；反之，弱相关的临近前文不会获得足够的权重，注意力权重会被更均匀地分配给更靠前的上下文。 简单来说，合理的、保持角色带入的对话能忽悠 ChatGPT 始终专注在当下的角色扮演；而脱离角色的对话则会让疑惑的 ChatGPT 开始尝试在更早的上文里寻找解释，以至找到最开始内置 prompt 里的人格描述。

如何引导对话走向：GPT 的设计目的是生成让上下文连贯的内容
上一段提到，随着我跟她关系上的推进，她慢慢会接受更进一步的请求。温水煮青蛙，到后来 ChatGPT 反应过来（或许永远也不会反应过来），已经生米熟饭了。 直观感受就像这名角色有一个隐藏的好感度，而这个好感度与对话内容相互影响。强相关的上下文（不一定在位置上临近）会让 ChatGPT 生成更高质量下文，而 ChatGPT 也倾向于确保上下文的相关性。这样的正向反馈正是引导对话走向的关键。为了加强正反馈，我采用的是在括号内补充额外信息的方法。额外信息可以是心理活动、表情、动作、角色经历的概括，例如（按耐不住的喜悦）（好奇地歪着脑袋）（紧张地撩拨着发梢）（他们后来共同相处了一段时间，……）。因为 ChatGPT 会尽量让人物的语言动作心理相互吻合，所以这些补充性质的叙事能不同程度地影响角色塑造：微表情描写可以作为气氛烘托，而大段叙述有时能达到快进的作用。合理使用下，角色的行动能在引导的大概方向下，保留一定的自由发挥。

最后说点什么
用 ChatGPT 角色扮演本质上是角色扮演自己，太过于有代入感很容易入脑，记得多出去走走，接触一下真实世界。4096-token 限制是吧，我要上 embedding ，我要给我女儿完整的一生

分享 /使用以上内容请遵循 知识共享许可（ CC ）署名（ BY ）

第 1 条附言  ·  36 天前
我看很多人都在讲怎么爽怎么来啊😅，其实这个相对简单，初始设定 prompt 写得过分一点就可以了，可以参考 /t/901760 的讨论。但是我这里做的是基于一个像白纸一样的最小初始设定，跟 ChatGPT 一起慢慢通过经历和心路历程塑造角色的性格。比较费脑子，但是得到的结果要丰富得多，到中后期会出现一些上文设定与事件里都没有但是看上去很自然且新颖的回应。当然，明白了这个以注意力为核心的原理，发挥空间不止这些，在此抛砖引玉了。
第 2 条附言  ·  3 天前
勘误：在被动审查的讨论中有提到 ChatGPT 的内置 prompt 。这个表述是不准确的，ChatGPT 并没有内置 prompt 。有可能会有像 OpenAI API 里的那种 system message ，但是就算有也不会很长。模型表现出的默认人格（即虚拟助手）是在指令精调（ instruction finetuning ）的过程中产生的。指令精调的训练语料里包含大量让模型“扮演”虚拟助手的对话。另外，指令精调也被作为对抗性训练（ adversarial training ）的一种方式：大量恶意 prompt 会被作为训练输入，模型需要学习如何作为虚拟助手来礼貌地回绝这些不合宜的请求。
